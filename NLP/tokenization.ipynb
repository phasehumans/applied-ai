{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7576,
     "status": "ok",
     "timestamp": 1757645691572,
     "user": {
      "displayName": "Chaitanya",
      "userId": "17149693889078725148"
     },
     "user_tz": -330
    },
    "id": "mRkob1yasdTb"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\conne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\conne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\conne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\conne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1757645695811,
     "user": {
      "displayName": "Chaitanya",
      "userId": "17149693889078725148"
     },
     "user_tz": -330
    },
    "id": "mplhD9jotaST"
   },
   "outputs": [],
   "source": [
    "text= \"An LLM is an advanced AI trained on massive text datasets.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1757645697231,
     "user": {
      "displayName": "Chaitanya",
      "userId": "17149693889078725148"
     },
     "user_tz": -330
    },
    "id": "SD5AnZL9t3MB",
    "outputId": "5e8aa38d-72d9-4792-913b-024046cf9b32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization >  ['an', 'llm', 'is', 'an', 'advanced', 'ai', 'trained', 'on', 'massive', 'text', 'datasets', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens= word_tokenize(text.lower())\n",
    "print(\"Tokenization > \", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1757645701241,
     "user": {
      "displayName": "Chaitanya",
      "userId": "17149693889078725148"
     },
     "user_tz": -330
    },
    "id": "emWk7wN_u5I6",
    "outputId": "51bcab1c-21eb-4e65-cb89-a677429f6ed8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"it'll\", 'we', 'had', 'down', \"won't\", 'to', 'he', 'theirs', 'his', 'they', \"i've\", 'but', 'most', 'as', 'have', 'her', 'on', 'weren', 'wouldn', \"you're\", \"i'll\", 'she', 'both', 'below', 'up', 'your', \"couldn't\", 'i', 'yourselves', 'a', 'ourselves', 'from', \"that'll\", 'at', 'me', 'mustn', 'will', 'until', 'aren', 'any', 'it', 'are', 'just', 'each', 'myself', 'by', 'haven', \"it's\", 't', 'while', 'own', \"he's\", 'because', 'why', 'can', \"we'll\", 'into', \"didn't\", 'hers', 'when', \"you'll\", 'more', 'off', 'won', 'or', 'some', 'against', 'isn', 'ain', 'doesn', \"haven't\", 'is', \"doesn't\", 'wasn', \"shan't\", \"weren't\", \"we've\", 'very', 'an', 'over', 'which', 'o', 'for', \"he'd\", \"hadn't\", 'yours', \"they'd\", 'before', \"isn't\", 'hadn', 'between', 'nor', 'mightn', \"hasn't\", 'such', 'does', 'who', 'after', 'herself', 'their', \"it'd\", 're', 'too', \"aren't\", \"he'll\", 'ma', 'ours', 'didn', \"we're\", 'him', 'there', \"we'd\", 'our', 'shan', 'those', 'where', 'do', 'having', 'was', 'itself', 'were', 've', 'in', 'being', \"mustn't\", 'should', \"they've\", \"wouldn't\", 'and', 'themselves', 'again', 'couldn', 'been', \"she'd\", 'all', 'yourself', \"don't\", 'then', 'am', 'how', 'if', 'no', 'out', 'my', 'under', \"wasn't\", 'above', 'needn', 'these', 'them', 'you', 'this', \"mightn't\", 'once', 'shouldn', 'd', 'don', \"they'll\", 'with', 'same', 'so', 'what', \"should've\", 'now', \"i'd\", \"shouldn't\", 'than', 's', \"you'd\", \"she's\", 'that', 'himself', 'hasn', 'doing', 'other', 'did', \"they're\", 'during', 'here', 'not', \"needn't\", \"you've\", 'm', 'has', 'y', 'about', 'be', 'few', 'its', \"she'll\", 'only', 'll', 'the', 'of', 'through', 'further', 'whom', \"i'm\"}\n",
      "198\n"
     ]
    }
   ],
   "source": [
    "stop_words= set(stopwords.words('english'))\n",
    "print(stop_words)\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1757645722109,
     "user": {
      "displayName": "Chaitanya",
      "userId": "17149693889078725148"
     },
     "user_tz": -330
    },
    "id": "0oqSa1vyx3Rn",
    "outputId": "73663992-49a5-40c5-f2bd-f12868bac004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['llm', 'advanced', 'ai', 'trained', 'massive', 'text', 'datasets', '.']\n",
      "['an', 'is', 'an', 'on']\n"
     ]
    }
   ],
   "source": [
    "filter_token= []\n",
    "remove_words= []\n",
    "\n",
    "for i in tokens:\n",
    "    if i not in stop_words:\n",
    "        filter_token.append(i)\n",
    "    else:\n",
    "        remove_words.append(i)\n",
    "\n",
    "print(filter_token)\n",
    "print(remove_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1757645723145,
     "user": {
      "displayName": "Chaitanya",
      "userId": "17149693889078725148"
     },
     "user_tz": -330
    },
    "id": "LdnAgQy5zXfG",
    "outputId": "0264f6b5-4c40-4266-baad-8fe4de13a465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['llm', 'advanc', 'ai', 'train', 'massiv', 'text', 'dataset', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer= PorterStemmer()\n",
    "\n",
    "stemmed_tokens= []\n",
    "for i in filter_token:\n",
    "  stemmed_tokens.append(stemmer.stem(i))\n",
    "\n",
    "print(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4137,
     "status": "ok",
     "timestamp": 1757645729081,
     "user": {
      "displayName": "Chaitanya",
      "userId": "17149693889078725148"
     },
     "user_tz": -330
    },
    "id": "w56omCta2x5i",
    "outputId": "13f1f6be-b58b-4270-eb00-0dd83d520dd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['llm', 'advanced', 'ai', 'trained', 'massive', 'text', 'datasets', '.']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer= WordNetLemmatizer()\n",
    "\n",
    "lemmatized_tokens= []\n",
    "for i in filter_token:\n",
    "  lemmatized_tokens.append(lemmatizer.lemmatize(i))\n",
    "\n",
    "print(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMr4MeLbfC3mxPmVFOZxs0Z",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
