### AI Overview

- what does it mean to learn?
    - building accuarate mental model to understand, predict and use
    - learning : confusion -> pattern recognition -> understanding -> prediction
- what is knowledge? what does it mean to know something?
    - mental model that represents how something works
    - understanding + structure + predictive power
        - why knowledge needs to be in structured, why not unstructure?
            - brain connect ideas, structure is req to build relationships
            - reasoning needs chaining; chain needs connection; unstructure knowledge dont have connections
            - structure : info -> understanding
    - child [2+2=4 -> memory]
    - but when child can do 3+3, and use to count obj
    - then child knows addition
    - knowing - ability to use mental model to understand, predict and act
- what is intelligence?
    - ability to observe, understand hidden patterns, predict outcomes, decide what to act/do
    - ability to build and use mental models to solve new problmes
    - not relying on just memory
- what is ai?
    - getting machines to perform tasks that req human intelligence
    - build there own understanding of world, act on it
    - figure it out
- hardcode intelligence (symbolic ai era)
    - how do we hardcode intelligence?
        - explicitly writing rules that tells machines what to do in every situation
        - if and then
        - rule based : encode expert knowledge
    - examples of rule based systems?
        - early chess engines
        - spam filters before ml
        - eliza chatbot
        - npc's in games
    - what were drawbacks that lead to ml?
        - rule based dont scale, adapt, generalize, improve over time
        - ambiguity
        - rules conflicting rules (rules about rules)
        - reality refuses to fit into rules
        - intelligence is not list of rules , it is process of learning from exp
        - stop telling machines what are rules, let them derive rules from data (rules --> patterns)
- machine learning
    - what is machine learning?
        - way to make computers learn patterns from data
        - itelligence = patterns discovery + generalization
        - adjust numbers (paramters) based on mistakes
        - learning lives in model
        - find mistakes through loss (error) and adjust parameters
        - ml dont try to be perfect, it try to be less wrong over time
    - types and examples of machine learning algorithms?
        - supervised learning - learn with answers/output
            - learning a mapping from input to output using labled(input + corrrect answer attach) examples
            - classification -> put into right bucket
                - spam/notspam, fraud/notfraud, cat/dog
                - draw boundries using past examples
                - knn
                - logistic regression
                - naive bayes
                - decision tree
                - random forest
                - svm (support vector machine)
            - regression -> predict a number
                - house price prediction, delivery time predicition
                - fn that map input ---> numbers
                - linear regression
                - polynomial regression
                - knn regression
                - decision tree regression
                - random forest regression
                - svr (support vector regression)
            - cant discover unknown patterns
            -need label data (expensive)
        - unsupervised learning - learns without answers
            - learning w/o label
            - explore data itself and discover structure, patterns
            - clustering -> discover grouping
                - grouping similar datapoints together w/o knowing groups in advance
                - k-means
                - hierarchical clustering (agglomerative and divisive)
                - dbscan
                - mean shift
                - gausssian mixture models
            - dimensionality reduction -> simplify complex data w/o losing meaning
                - represnt high dimension data into fewer and meaningful dimension
                - pca (principal component analysis)
                - t-sne
                - umap
                - autoencoders
            - anomaly detection -> spot unusual
                - far from avg
                - far from neighbors
                - sparse density
                - tiny clusters
                - isolation forest
        - reinforcement learning - learn from reward and punishment
            - learn by doing, not by being told
            - learn from consequences, not answers
            - agent, env, state, action, reward
            - value based methods -> how good is this situation
                - q-learning
            - policy based methods -> what should i do |state --> action|
            - actor-crictic methods -> one act, one judge
            - model based rl -> think before act
            - rl rewards are sparse
            - training is unstable
            - not prediction, but control
        - semi-supervised learning - little guidance, a lot of exploration (few labels + lot of data)
        - self-supervised learning - learning by creating own tasks (predict missing info) --> base of llms
    - what are important concepts in ml?
        - data
        - features - measurements, properties, signals
        - parameters - internal numbers inside model that store what model has learned from data
        - model - fn w/ parameters
        - loss fn - distance betn prediction and reality
        - learning - reducing loss fn
        - optimization - process of adjust model (fn w/ para)
        - generalization - performace on unseen data
        - overfitting - memorized noise
        - underfitting - didn't learn enough
        - bias - simplicity
        - variance - sensitivity
        - evaluation metrics - accuracy, precision, recall
        - hyperparameters -  controllers for learning rate
        - assumptions - hidden beliefs
    - fundamental diff betn ml and dl?
        - feature engineering - tell model what to look for
        - ml cant learn good representation by itself
        - in dl, models auto learn hierarchical features from raw data using layers
        - ml : input + feat-eng --> output
        - dl : input --->  layer | layer | layer | layer | ...| layers | ---> output
    - what are fundamentals of ml that are carry forward to dl and transformers?
        - core of ml -> guess > measure error > adjust > repeat
        - representation
        - model is still fn with parameters
            - what are parameters?
                - numbers that represent learning
                - learned numbers / memory of models
                - weight
                - bias
        - loss fn; goal is to reduce loss
        - optimization
        - generalization
    - what drawbacks of ml that leads to neural networks?
        - classical ml cant learn representations by itself
        - real world data is non-linear and complex
        - cant represent hierarchical concepts
        - manual feat eng
        - cant learn representation
        - neural networks for representation learning
- neural networks
    - what are neural networks?
        - learns by applying many small transformations in sequence, where is each transformations builds on prev one
        - to build models, that can learn in layers
        - neurons - tiny pattern detectors
        - layers - abstraction levels
        - parameters - learned knowledge
    - how does the nueral networks are actually trained?
        - input -> vector of numbers (image - pixel, text - token, audio - wave amplitudes)
        - forward propagation - structured guess
        - back propagation - traces responsibility backward and assigns blame proportionally
        - parameters are updated to reduce loss
        - networks dont understand concepts, it reacts to patterns
        - loop:
            - inputs go forward
            - network predicts output
            - loss is calculated
            - errors flow backward
            - parameters are adjusted
    - what is rnn?
        - invented to give nueral networks memory
        - nn that passes info from one step to next, so it can remember the past
        - hidden state is memory of nn
        - hidden state is vector of numbers, that summarizes everything seen so far
        - rnn memory is fragile and slow
    - how rnn is different from nueral network?
        - rnn is neural network
        - normal nn has no memory, treats each input independently
        - rnn feeds its previos output back into itself
        - nn : input --> |layers| --> output
        - rnn : input --> memory1 ; input + memory1 ---> memory2 ; ....
    - examples of rnn?
        - predictive keyboards
        - early google translation
    - what are limitations of rnn?
        - weak long term memory
        - training is slow
        - attention is better
    - diff betn cnn and rnn?
        - cnn for image / space
        - rnn for sequence / time
        - cnn process parallel
        - rnn process sequentail
    - why it is harder for nets to understand language over image?
        - image is spatial
        - language is sequential and contextual
        - pixels that matter are physically near to each other
        - imp words that matter, might be far apart in the sequence, long range dependency
        - language req remembering and relating info across distances
    - what are sequence models?
        - neural net treats every input has independent
        - but lang, stock price, music; each input depends upon its prev
        - so, models that are designed to handle data where order and context matter
        - process one elmt at time, maintain memory(state)
        - ex. rnn, lstm
    - does transformer is also part of sequence models?
        - yes, but use attention instead of recurrent memory
        - sequence model is not any architecture
        - any model that handle ordered data, use context
        - old soln : rnn, lstm, gru; they pass hidden state(that is what i saw in the past)
        - but this memory fades over long sequence
        - new soln : attention-based models
        - look everything at once, decide what matters and connect them directly
    - why do rnn, lstm, bert and other models fail?
        - rnn process step by step and carry hidden state(memory : compress info) forward
        - at longer seq, info loss; forget long term dependencies
        - in lstm added gates to control memory
        - but still sequential and recurrence, no full context access
        - cnn look for local neighborhoods, design for spatial patterns
        - bert is not fail, it is transformer
        - understanding but not genrational
        - bert -> gpt
        - rnn, lstm, gru all needed a mechnaism that allows direct, global, || interaction betn all elmt of seq
        - soln is attention
- attention
    - what is attention?
        - mechanism that let model decide what parts of the input matter right now
        - model decide where to focus
        - not memory, but selective focus, contextual lookup
        - mechanism that allows model to dynamically focus on the most relevant parts of the input when producing output
    - why attention is powerful than nueral nets?
        - rnn compression loss info
        - rnn cant decide which info matters right now
        - attention can selective focus
        - direct conection, no compression
        - parallel reasoning and understand relationships
- transformer
    - what is transformer?
        - architecture that process entire sequence at once, no recurrence
        - 2 steps - self attention and feed forward
        - self attention - decide what to focus on, evry word look at every other word
        - multiple layers of attention
        - improved when scale
    - how chatgpt works?
        - gpt predicts the next word/token
        - to predict, it needs to understand input
        - predict next word based on prev words has inputs
        - raw models are trained to complete next word
        - finetune needed for qa style
        - rlhf learning, good ans and bad ans test
        - input -> convert to token -> pass in trans layers -> attention build relation -> layers -> next word predict ; repeat till ans complete
    - how models are trained?
        - learning = improving guesses
        - loss -> how bad predicition is
        - learning : guess -> measure loss -> reduce loss -> repeat
        - parameters store what the model has learned; learning is adjusting this numbers
            - how does numbers stores the learning?
                - weigths: how strongly one nueron influences another
                - biases: offset number
                - parameters = weights + biases (parameter decide how strongly one feature influences another)
                - learning is finding right transformation
                - finding right numbers, so that it will lead input into desired output
                - inshort finding numbers that represents reality
                - knowledge is not stored in individual neuron but in geometry of parameter space
                - after training/ updating para billions of time, networks internal geometry becomes a compressed model of reality
                - structure of relationship
                - parameters store patterns of transformation
        - forward propagation for prediction
        - backward propagation to correct mistakes
        - input data -> forward pass : prediction -> loss calculation -> backpropagation : assign blame -> gradient descent -> repeat
        - ai learns the statistical structure of reality encoded in data
    - why predicting next word creates understanding?
        - "i put the icream in the freezer so that it would not ...."
        - why memorization dont work
        - "the purple elephant danced on the keyboard while drinking coffee"
        - humans dont memorize examples, humans understand language structure
        - to predict next word/token, model needs to build internal simulation of reality
        - prediction -> representation -> understanding
        - compress massive experience/internet into compact internal structure/reality
        - "If all mammals breathe oxygen, and whales are mammals, then whales breathe ..."
        - model was not trained to reason, but it had to reason to predict next word
        - understanding, reasoning is not train directly, it emerges as side effect of prediction
    - how reasoning gets emerges in models?
        - reasoning - ability to chain ideas logically to reach new conclusions
        - attention is require; to link distant concepts and relationship
        - reasoning is compressed simulation
    - how do hallucinations happen?
        - confident sounding incorrect/fabricated info
        - model is design to predict next most likely token, not to verify truth, not to check reality
        - way to represebt fact is learned by model, how confident language looks, how humans present facts
        - it has all learned, so it shows confidence while fabricating, leads to false confidence
        - rag + search reduce hallucinations
        - models are train to continue, not check reality
        - for hallucination, input needs to be high pattern simlarity : scientific discovery → physicist → institute → paper → year
    - what is foundational models?
        - general purpose intelligence
        - general representation of reality
    - what is llm?
        - large language model
        - large number of parameters - billion to trillion
        - gpt4, claude, gemini
    - what is slm?
        - small language model
        - smaller number of parameters - million
        - phi-2, mistral7b, distilBERT
    - what are other architecture than transformer?
        - feedforward neural networks (fnn)
        - convolutional neural networks (cnn)
        - recurrent neural networks (rnn)
        - long short term memory (lstm)
        - gated recurrent unit (gru)
        - graph neural networks (gnn)
        - capsule networks
        - autoencoders
        - diffusion models
        - state space models(ssm) - s4, mamba, rwkv -> o(n)
        - neural turing machines - nets + ram
        - modular neural nets
        - world model architectures - deepminde mu0, dreamer, gato
        - agent architectures - autogpt, react, tree of thoughts
--- 
- [LLM visualization](https://bbycroft.net/llm)
- attention is all you need (transformer paper)